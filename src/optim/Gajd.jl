#  Unit "Gajd.jl" of the Diagonalization.jl Package for Julia language
#
#  MIT License
#  Copyright (c) 2019,
#  Marco Congedo, CNRS, Grenoble, France:
#  https://sites.google.com/site/marcocongedo/home

# ? CONTENTS :
#  This unit implements the Gauss AJD algorithm of Congedo (unpublished).

#  The algorithm handles the AJD diagonalization procedure, corresponding
#  to the case m=1, k>1 according to the taxonomy adopted in this package.


# update input matrices and AJD matrix for Gauss Algorithms
# bj <- bj +  Î¸bi (update the jth column with respect to the ith one)
# Cpj <- bp' C (bj +  Î¸bi) for p=1:n (jth row of C)
# Cjq <- (bj +  Î¸bi)'' C bq  for q=1:n (jth column of C)
# the update of C is done only on the lower triangular part
# ğ‹ is a lower triangular matrix of k-length vectors : ğ‹[i, j][k]=C[k][i, j]
@inline function _update1!(j, i, n, Î¸, Î¸Â², ğ‹, B) # i>j
   for p = 1:j-1 ğ‹[j, p] += Î¸*ğ‹[i, p] end     # update ğ‚ :
   ğ‹[j, j] += Î¸Â²*ğ‹[i, i] + 2Î¸*ğ‹[i, j]         # write jth row and column
   for p = j+1:i ğ‹[p, j] += Î¸*ğ‹[i, p] end     # only on the lower
   for p = i+1:n ğ‹[p, j] += Î¸*ğ‹[p, i] end     # triangular part.
   B[:, j] += Î¸*B[:, i]                       # update B
end

# update1! takes care of the udpate if i>j, update2! if jâ‰¥i
@inline function _update2!(j, i, n, Î¸, Î¸Â², ğ‹, B) # j>i
   for p = 1:i-1 ğ‹[j, p] += Î¸*ğ‹[i, p] end     # update ğ‚ :
   for p = i:j-1 ğ‹[j, p] += Î¸*ğ‹[p, i] end     # write jth row and column
   ğ‹[j, j] += Î¸Â²*ğ‹[i, i] + 2Î¸*ğ‹[j, i]         # only on the lower
   for p = j+1:n ğ‹[p, j] += Î¸*ğ‹[p, i] end     # triangular part.
   B[:, j] += Î¸*B[:, i]                       # update B
end


#  PRIMITIVE GAJD algorithm:
#  It takes as input a lower triangular matrix
#  holding in its elements vectors of k real numbers.
#  From data in matrix form given as k symmetric C_Îº matrices of size nxn,
#  we have ğ‹[i, j][Îº] = C_Îº[i, j], for Îº=1:k, i>j=1:n.
#  It finds a non-singular matrix B such that the
#  congruences B'*C_Îº*B are as diagonal as possible for all Îº=1:k.
#  `tol` is the convergence to be attained.
#  `maxiter` is the maximum number of iterations allowed.
#  if `verbose`=true, the convergence attained at each iteration and other
#  information will be printed.
#  RETURN: B, the number of iterations and the convergence attained (a 3-tuple)
function gajd(ğ‹::AbstractArray; tol = 0., maxiter = 60, verbose = false)

   # find optimal theta and update convergence (âˆ¡)
   function _gauss!(ğ‘–, ğ‘—, i) # ğ‘– must be < ğ‘—
      Î¸  = h*sum(ğ‹[ğ‘—, ğ‘–].*ğ‹[i, i])
      Î¸Â² = Î¸^2
      âˆ¡ += Î¸Â²
   end

   @inline function congedoSweep!()
      âˆ¡ = T(0.)
      for i = 1:n
         h = -inv(sum(ğ‹[i, i].^2)) # h is invariant in the inner loop

         # transform all jâ‰ i columns of B with respect to its ith column:
         for j = 1:i-1
            _gauss!(j, i, i) # find Î¸, Î¸Â² and update âˆ¡
            _update1!(j, i, n, Î¸, Î¸Â², ğ‹, B) # update ğ‹ and B given Î¸ and Î¸Â²
         end
         for j = i+1:n
            _gauss!(i, j, i) # find Î¸, Î¸Â² and update âˆ¡
            _update2!(j, i, n, Î¸, Î¸Â², ğ‹, B) # update ğ‹ and B given Î¸ and Î¸Â²
         end
      end
      return âˆš(âˆ¡ * e) # convergence: average squared theta over all n(n-1) pairs
   end

   # declare variables
   T, n = eltype(ğ‹[1, 1]), size(ğ‹, 1)
   h, Î¸, Î¸Â², âˆ¡, e = T(0), T(0), T(0), T(0), T(inv(n*(n-1)))
   B = Matrix{T}(I, n, n) # initialization of the AJD matrix

   iter, conv = _iterate!("GOFF", congedoSweep!, maxiter, T, tol, verbose)

   return B, iter, conv
end



#  ADVANCED GAJD algorithm:
#  It takes as input a vector of k real symmetric matrices ğ‚ and finds a
#  non-singular matrix B such that the congruences B'*ğ‚_Îº*B are as diagonal
#  as possible for all Îº=1:k.

#  if `trace1` is true (false by default), all input matrices are normalized
#  so as to have unit trace. Note that the diagonal elements
#  of the input matrices must be all positive.
#
#  `w` is an optional vector of k positive weights for each matrix in ğ‚.
#  if `w` is different from `nothing` (default), the input matrices are
#  weighted with these weights (after trace normalization if `trace1` is true).
#  A function can be passed as the `w` argument, in which case the kth weight
#  is found as the output of the function applied to the kth matrix in ğ‚.
#  A good choice in general is the `nonD` function declared in tools.jl unit.
#
#  if `whitening` = true is passed, the Arithmetic mean of the matrices in ğ‚ is
#  computed (using the PosDefManifold.jl package) and the matrices in ğ‚
#  are pre-transformed using the whitening matrix of the mean.
#  Dimensionality reduction can be obtained at this stage using optional
#  arguments `eVar` and `eVarMeth` (see documentation of the AJD constructors).
#
#  if sort=true (default) the column vectors of the B matrix are normalized
#  to unit norm and permuted so as to sort in descending order the mean over
#  Îº=1:k of the diagonal elements of B'*ğ‚_Îº*B.
#  Note that if `whitening` is true the output B will not have unit norm columns
#  as it is multiplied by the whitener after being scaled and sorted
#  and before being returned.
#
#  if  `whitening` = false (default), a matrix can be provided with the `init`
#  argument in order to initialize B. In this case the actual AJD
#  will be given by init*B, where B is the output of the algorithm.
#
#  `tol` is the convergence to be attained.
#
#  `maxiter` is the maximum number of iterations allowed.
#
#  if `verbose`=true, the convergence attained at each iteration and other
#  information will be printed.
#
#  return: B, its pseudo-inverse, the mean diagonal elements of B'*mean(ğ‚)*B,
#          the number of iterations and the convergence attained
#
#  NB: Differently from other AJD algorithms, this algorithm proceeds
#  by transformations of one vector at a time given a pair of vectors of B.
#  A sweep goes over all n*(n+1) ij pairs, with i,j âˆˆ 1:n, jâ‰ i.
#  The update of the input matrices is RECURSIVE, thus it is not suitable
#  for multi-threading. This algorithm has the lowest complexity per iteration
#  among all algorithms here implemented and scale extremely well over k, i.e.,
#  for n small and k large it offers the best performance.
function gajd( ğ‚::Union{Vector{Hermitian}, Vector{Symmetric}};
               trace1   :: Bool  = false,
               w        :: Twf   = â—‹,
               preWhite :: Bool  = false,
               sort     :: Bool  = true,
               init     :: Union{Matrix, Nothing} = â—‹,
               tol      :: Real  = 0.,
               maxiter  :: Int   = 120,
               verbose  :: Bool  = false,
            eVar     :: TeVaro = â—‹,
            eVarMeth :: Function = searchsortedfirst)

   # trace normalization and weighting
   ğ† = _normalizeAndWeight(trace1, w, ğ‚)

   # pre-whiten or initialize or nothing
   W = _preWhiteOrInit!(ğ†, preWhite, Euclidean, eVar, eVarMeth, init)

   T, n = eltype(ğ†[1]), size(ğ†[1], 1)

   # arrange data in a LowerTriangular matrix of k-vectors
   ğ‹ = _arrangeData!(T, n, ğ†)

   B, iter, conv = gajd(ğ‹; tol=tol, maxiter=maxiter, verbose=verbose)

   # scale and permute the vectors of B
   D=Diagonal([mean(ğ‹[i, i]) for i=1:n])
   Î» = sort ? _permute!(_scale!(B, D, n)...) : diag(D)

   return preWhite ? (W.F*B, pinv(B)*W.iF, Î», iter, conv) :
                     (B, pinv(B), Î», iter, conv)
end




function gLogLike(ğ‹::AbstractArray; tol = 0., maxiter = 60, verbose = false)

   # find optimal theta and update convergence âˆ¡
   function _gauss!(ğ‘–, ğ‘—, i, j) # ğ‘– must be < ğ‘—
      #=
      fill!(Î , T(1))
      for l=1:ğ‘–-1 Î .*=ğ‹[l, l] end # much faster without the if!
      for l=ğ‘–+1:ğ‘—-1 Î .*=ğ‹[l, l] end
      for l=ğ‘—+1:n Î .*=ğ‹[l, l] end
      =#

      Î _=Î ./ğ‹[j, j]  # ğ‹[ğ‘—, ğ‘–] here below picks from lower triangular part
      Î¸ = -sum(@. ğ‹[ğ‘—, ğ‘–]*ğ‹[i, i]*Î _) / sum(@. ğ‹[i, i]^2 *Î _)
      ####Î¸ = -sum(@. láµ¢â±¼*láµ¢áµ¢*Î ) / sum(láµ¢áµ¢Â² .*Î )
      Î¸Â² = Î¸^2
      âˆ¡ += Î¸Â²
   end

   @inline function congedoSweep!()
      âˆ¡ = T(0.)
      for i = 1:n
         # product of the diagonal elements excluding the ith one (for each k)
         fill!(Î , T(1))
         for l = 1:i-1 Î  .*= ğ‹[l, l] end
         for l = i+1:n Î  .*= ğ‹[l, l] end

         # transform all jâ‰ i columns of B with respect to its ith column:
         for j = 1:i-1
            _gauss!(j, i, i, j) # find Î¸, Î¸Â² and update âˆ¡
            _update1!(j, i, n, Î¸, Î¸Â², ğ‹, B) # update ğ‹ and B given Î¸ and Î¸Â²
         end
         for j = i+1:n
            _gauss!(i, j, i, j) # find Î¸, Î¸Â² and update âˆ¡
            _update2!(j, i, n, Î¸, Î¸Â², ğ‹, B) # update ğ‹ and B given Î¸ and Î¸Â²
         end
      end
      return âˆš(âˆ¡ * e) # convergence: average squared theta over all n(n-1) pairs
   end

   # declare variables
   T, n = eltype(ğ‹[1, 1]), size(ğ‹, 1)
   Î  = Vector{T}(undef,  length(ğ‹[1, 1])); Î _= similar(Î )
   Î¸, Î¸Â², âˆ¡, e = T(0), T(0), T(0), inv(n*(n-1))
   B = Matrix{T}(I, n, n) # initialization of the AJD matrix

   iter, conv = _iterate!("GLogLike", congedoSweep!, maxiter, T, tol, verbose)
   return B, iter, conv
end


function gLogLike( ğ‚::Union{Vector{Hermitian}, Vector{Symmetric}};
               w        :: Twf   = â—‹,
               preWhite :: Bool  = false,
               sort     :: Bool  = true,
               init     :: Union{Matrix, Nothing} = â—‹,
               tol      :: Real  = 0.,
               maxiter  :: Int   = 120,
               verbose  :: Bool  = false,
            eVar     :: TeVaro = â—‹,
            eVarMeth :: Function = searchsortedfirst)

   # pre-whiten or initialize or nothing
   W, ğ† = _preWhiteOrInit(ğ‚, preWhite, Jeffrey, eVar, eVarMeth, init, :Hvector)

   T, n = eltype(ğ†[1]), size(ğ†[1], 1)

   # arrange data in a LowerTriangular matrix of k-vectors
   ğ‹ = _arrangeData!(T, n, ğ†)

   B, iter, conv = gLogLike(ğ‹; tol=tol, maxiter=maxiter, verbose=verbose)

   # scale and permute the vectors of B
   D=Diagonal([mean(ğ‹[i, i]) for i=1:n])
   Î» = sort ? _permute!(_scale!(B, D, n)...) : diag(D)

   return preWhite ? (W.F*B, pinv(B)*W.iF, Î», iter, conv) :
                     (B, pinv(B), Î», iter, conv)
end


# approximation computing in the outer loop the products of the diagonal
# elements discarding the ith elements. This does not discared the jth
# element in the inner loop
function gLogLike_(ğ‹::AbstractArray; tol = 0., maxiter = 60, verbose = false)

   # find optimal theta and update convergence âˆ¡
   function _gauss!(ğ‘–, ğ‘—, i, j) # ğ‘– must be < ğ‘—
      Î¸  = sum(@.ğ‹[ğ‘—, ğ‘–]*láµ¢áµ¢) * Ï‰
      Î¸Â² = Î¸^2
      âˆ¡ += Î¸Â²
   end

   @inline function congedoSweep!()
      âˆ¡ = T(0.)
      for i âˆˆ 1:n

         # approximation
         fill!(Î , T(1))
         for l=1:i-1 Î .*=ğ‹[l, l] end
         for l=i+1:n Î .*=ğ‹[l, l] end
         láµ¢áµ¢=ğ‹[i, i].*Î 
         Ï‰=-inv(sum(ğ‹[i, i].^2 .*Î ))

         for j = 1:i-1
            _gauss!(j, i, i, j) # find Î¸, Î¸Â² and update âˆ¡
            _update1!(j, i, n, Î¸, Î¸Â², ğ‹, B) # update ğ‹ and B given Î¸ and Î¸Â²
         end
         for j = i+1:n
            _gauss!(i, j, i, j) # find Î¸, Î¸Â² and update âˆ¡
            _update2!(j, i, n, Î¸, Î¸Â², ğ‹, B) # update ğ‹ and B given Î¸ and Î¸Â²
         end
      end
      return âˆš(âˆ¡ * e) # convergence: average squared theta over all n(n-1) pairs
   end

   # declare variables
   T, n = eltype(ğ‹[1, 1]), size(ğ‹, 1)
   Î  = Vector{T}(undef,  length(ğ‹[1, 1]));
   Î _, láµ¢áµ¢ = similar(Î ), similar(Î )
   Î¸, Î¸Â², âˆ¡, Ï‰, e = T(0), T(0), T(0), T(0), inv(n*(n-1))
   B = Matrix{T}(I, n, n) # initialization of the AJD matrix

   iter, conv = _iterate!("GLogLike_", congedoSweep!, maxiter, T, tol, verbose)
   return B, iter, conv
end


function gLogLike_( ğ‚::Union{Vector{Hermitian}, Vector{Symmetric}};
               w        :: Twf   = â—‹,
               preWhite :: Bool  = false,
               sort     :: Bool  = true,
               init     :: Union{Matrix, Nothing} = â—‹,
               tol      :: Real  = 0.,
               maxiter  :: Int   = 120,
               verbose  :: Bool  = false,
            eVar     :: TeVaro = â—‹,
            eVarMeth :: Function = searchsortedfirst)

   # pre-whiten or initialize or nothing
   W, ğ† = _preWhiteOrInit(ğ‚, preWhite, Jeffrey, eVar, eVarMeth, init, :Hvector)

   T, n = eltype(ğ†[1]), size(ğ†[1], 1)

   # arrange data in a LowerTriangular matrix of k-vectors
   ğ‹ = _arrangeData!(T, n, ğ†)

   # run AJD algorithm
   B, iter, conv = gLogLike_(ğ‹; tol=tol, maxiter=maxiter, verbose=verbose)

   # scale and permute the vectors of B
   D=Diagonal([mean(ğ‹[i, i]) for i=1:n])
   Î» = sort ? _permute!(_scale!(B, D, n)...) : diag(D)

   return preWhite ? (W.F*B, pinv(B)*W.iF, Î», iter, conv) :
                     (B, pinv(B), Î», iter, conv)
end
