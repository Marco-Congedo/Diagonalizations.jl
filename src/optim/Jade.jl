#  Unit "Jade.jl" of the Diagonalization.jl Package for Julia language
#
#  MIT License
#  Copyright (c) 2019-2025
#  Marco Congedo, CNRS, Grenoble, France:
#  https://sites.google.com/site/marcocongedo/home
#  Konstantin Usevich, CNRS, Nancy, France
#  http://w3.cran.univ-lorraine.fr/konstantin.usevich/?q=content/home


# ? CONTENTS :
#  This unit implements two orthogonal AJD algorithms:
#  1) The famous JADE algorithm of Cardoso and Souloumiac (1996),
#  performing GIVENS ROTATIONS of p,q pairs of vectors according to
#  the CYCLIC SCHEME, i.e., all p,q pairs are rotated in the order
#  for all p=1:n-1, q=i+1:n.
#  The code here below is optimized for both real and complex data input and
#  has been adapted in Julia from code freely made available from the authors.
#  J.-F. Cardoso, A. Souloumiac (1996) Jacobi angles for simultaneous
#  diagonalization. SIAM Journal on Matrix Analysis and Applications,
#  17(1), 161â€“164.
#  2) The JADEmax algorithm proposed by Usevich, Li and Comon (2020).
#  This uses the same GIVENS ROTATIONS however the p,q pairs are chosen
#  as the pair corresponding to the maximum p,q entry of the Riemannian
#  gradient of the cost function. The convergence is much faster in this case
#  at an extra cost of updating the gradient after each rotation.
#  Simulations and tests on real data indicate that JADEmax is overall faster
#  for n>20.
#
#  NB: JADE may be optimized by multi-threading the optimization of the pairs
#  e.g., using the round-Robin tournament scheme.
#  On the other hand, JADEmax is by definition a sequential procedure.

#  These algorithms handle the AJD diagonalization procedure corresponding
#  to the case m=1, k>1 according to the taxonomy adopted in this package.


## Compute the Givens angle (sine, cosine) for p,q pair
# and corrsponding p,q gradient element for real data
@inline function givensAngle(C::Matrix{T}, p, q, ğ“¹, ğ“º,
							  eâ‚, eâ‚‚, eâ‚ƒ, Î¦, Î¦â‚œ) where T <:Real
  eâ‚[:] = C[p, ğ“¹] - C[q, ğ“º]
  eâ‚‚[:] = C[p, ğ“º] + C[q, ğ“¹]
  a = eâ‚â‹…eâ‚ - eâ‚‚â‹…eâ‚‚
  b = 2. * eâ‚â‹…eâ‚‚
  Î¸ = 0.5 * atan(b, a + âˆš(a^2 + b^2))
  s, c = sincos(Î¸)
  return c, s, abs(s), abs(b/4) # b/4 is the gradient
end

# Compute the Givens angle (sine, cosine) for p,q pair
# and corrsponding p,q gradient element for complex data
@inline function givensAngle(C::Matrix{T}, p, q, ğ“¹, ğ“º,
								eâ‚, eâ‚‚, eâ‚ƒ, Î¦, Î¦â‚œ) where T <:Complex
  eâ‚[:] = C[p, ğ“¹] - C[q, ğ“º]
  eâ‚‚[:] = C[p, ğ“º]
  eâ‚ƒ[:] = C[q, ğ“¹]
  E = Hermitian(UpperTriangular{T}([eâ‚â‹…eâ‚ eâ‚‚â‹…eâ‚ eâ‚ƒâ‹…eâ‚; 0. eâ‚‚â‹…eâ‚‚ eâ‚ƒâ‹…eâ‚‚; 0. 0. eâ‚ƒâ‹…eâ‚ƒ]))
  Î“ = real(Î¦*E*Î¦â‚œ)
  ğ›‰ = eigvecs(Î“)[:, 3] # Julia sorts the eigvecs; the 3rd<->max ev
  if real(ğ›‰[1])<0. ğ›‰ = -ğ›‰ end  # added 'real' to prevent error
  c = âˆš(0.5 + ğ›‰[1]/2.)         # cosine
  s = 0.5*(ğ›‰[2] - ğ›‰[3]im)/c   # sine
  return c, s, abs(s), abs(Î“[1, 2]+Î“[1, 3]im) # Î“[1, 2]+Î“[1, 3]im is the gradient
end


# Update U and all Câ‚– matrices by a Givens rotation (both real and complex data)
@inline function jadeUpdate!(U, C, c, s, p, q, ğ“¹, ğ“º)
	G = [c -conj(s); s c]
	âŠ¶ = [p, q]  # p,q index pair
	U[:, âŠ¶] = U[:, âŠ¶]*G
	C[âŠ¶, :] = G'*C[âŠ¶, :]
	C[:, [ğ“¹ ğ“º]] = [c*C[:, ğ“¹]+s*C[:, ğ“º] -conj(s)*C[:, ğ“¹]+c*C[:, ğ“º]]
end


# Do one cyclic sweep: rotate p,q pairs for all p=1:n-1, q=i+1:n
# For each p,q pair update U and all Câ‚– if max abs(sine(p,q angle))>tol
# Return max abs(sine(p,q angle)) over all pairs
@inline function cyclicSweepAngle!(C, eâ‚, eâ‚‚, eâ‚ƒ, Î¦, Î¦â‚œ, U, n, nk, tolerance)
  âˆ¡ = 0.
  @inbounds for p = 1:n-1
	 ğ“¹ = p:n:nk
	 for q = p+1:n
		ğ“º = q:n:nk
		c, s, ğ“ˆ, g = givensAngle(C, p, q, ğ“¹, ğ“º, eâ‚, eâ‚‚, eâ‚ƒ, Î¦, Î¦â‚œ)
		ğ“ˆ > tolerance ? jadeUpdate!(U, C, c, s, p, q, ğ“¹, ğ“º) : nothing
		âˆ¡ = max(âˆ¡, ğ“ˆ)  # ğ“ˆ is abs(sine of the p,q Givens angle)
	 end
  end
  return âˆ¡
end

# Do one cyclic sweep: rotate p,q pairs for all p=1:n-1, q=i+1:n
# For each p,q pair update U and all Câ‚– if abs(p,q gradient's element)>tol
# Return the maximum of abs(p,q gradient's element) over all pairs
@inline function cyclicSweepGradient!(C, eâ‚, eâ‚‚, eâ‚ƒ, Î¦, Î¦â‚œ, U, n, nk, tolerance)
  âˆ‡pq = 0.
  @inbounds for p = 1:n-1
	 ğ“¹ = p:n:nk
	 for q = p+1:n
		ğ“º = q:n:nk
		c, s, ğ“ˆ, g = givensAngle(C, p, q, ğ“¹, ğ“º, eâ‚, eâ‚‚, eâ‚ƒ, Î¦, Î¦â‚œ)
		g > tolerance ? jadeUpdate!(U, C, c, s, p, q, ğ“¹, ğ“º) : nothing
		âˆ‡pq = max(âˆ‡pq, g)  # g is abs(of p,q Riemannian gradient's element)
	 end
  end
  return âˆ‡pq
end


# Compute and return the Riemannian gradient (real data)
@inline function jadeRiemannianâˆ‡(C::Matrix{T}, D, n, k, ğ“¹â‚, ğ“¹â‚‚) where T <:Real
	âˆ‡=zeros(T, n, n)
	@inbounds @simd for i=1:k
		Câ‚– = C[:, ğ“¹â‚[i]: ğ“¹â‚‚[i]]
		D[i][:] = diag(Câ‚–)
		âˆ‡ += Câ‚–.*D[i]'
	end
	return âˆ‡-âˆ‡'
end


# Compute and return the Riemannian gradient (Complex data)
@inline function jadeRiemannianâˆ‡(C::Matrix{T}, D, n, k, ğ“¹â‚, ğ“¹â‚‚) where T <:Complex
	âˆ‡=zeros(T, n, n)
	@inbounds @simd for i=1:k
		Câ‚– = C[:, ğ“¹â‚[i]: ğ“¹â‚‚[i]]
		D[i][:] = conj(diag(Câ‚–))
		âˆ‡ += Câ‚–.*(transpose(D[i])) - Câ‚–.*D[i] # the @. macro transform all ensuing operations in breadcasting element-wise operations
	end
	return âˆ‡-âˆ‡'
end


# Update the p, q rows and columns of the gradient
@inline function jadeRiemannianâˆ‡Update!(âˆ‡, C::Matrix{T}, D, k, p, q, ğ“¹, ğ“º, ğ“¹â‚, ğ“¹â‚‚) where T <:Real
	âŠ¶ = [p, q]  # p,q index pair
	âˆ‡[:, âŠ¶] .= T(0)
	@inbounds @simd for i=1:k
		dp, dq = C[p, ğ“¹[i]], C[q, ğ“º[i]]
		D[i][p], D[i][q] = dp, dq
		âˆ‡[:, âŠ¶] += [C[:, ğ“¹[i]].*(dp.-D[i]) C[:, ğ“º[i]].*(dq.-D[i])]
	end
	âˆ‡[âŠ¶, :]=-âˆ‡[:, âŠ¶]'
end


# Update the p, q rows and columns of the gradient
@inline function jadeRiemannianâˆ‡Update!(âˆ‡, C::Matrix{T}, D, k, p, q, ğ“¹, ğ“º, ğ“¹â‚, ğ“¹â‚‚) where T <:Complex
	âŠ¶ = [p, q]  # p,q index pair
	âˆ‡[:, âŠ¶] .= T(0)
	#@inbounds @simd for i=1:k
	for i=1:k
		dp, dq = conj(C[p, ğ“¹[i]]), conj(C[q, ğ“º[i]])
		D[i][p], D[i][q] = dp, dq
		âˆ‡[:, âŠ¶] += [(C[:, ğ“¹[i]].*(dp.-D[i]).+conj.(C[p, ğ“¹â‚[i]:ğ“¹â‚‚[i]]).*conj.(dp.-D[i])) (C[:, ğ“º[i]].*(dq.-D[i]).+conj.(C[q, ğ“¹â‚[i]:ğ“¹â‚‚[i]]).*conj.(dq.-D[i]))]
		#âˆ‡[:, âŠ¶] += [C[:, ğ“¹[i]].*(dp-D[i])+conj(C[p, ğ“¹â‚[i]:ğ“¹â‚‚[i]])*conj(dp.-D[i]) C[:, ğ“º[i]].*(dq.-D[i])+conj(C[q, ğ“¹â‚[i]:ğ“¹â‚‚[i]])*conj(dq.-D[i])]
	end
	âˆ‡[âŠ¶, :]=-âˆ‡[:, âŠ¶]'
end


# pre-allocate memory
@inline function jadeAllocateMemory(T, k)
	eâ‚ = zeros(T, k)
	eâ‚‚ = zeros(T, k)
	if T <:Complex
		eâ‚ƒ = zeros(T, k)
		Î¦ = convert(Matrix{T}, [1 0 0; 0 1 1; 0 -im im])
		Î¦â‚œ = Î¦'
	else
		eâ‚ƒ, Î¦, Î¦â‚œ = nothing, nothing, nothing, nothing
	end
	return eâ‚, eâ‚‚, eâ‚ƒ, Î¦, Î¦â‚œ
end


## PRIMITIVE JADE (Cyclic) algorithm:
#  It takes as input a nÂ·nk matrix holding k horizontally stacked nÂ·n real or
#  complex matrices, such as C=[C_1...C_k].
#  It finds an orthogoanl/unitary matrix U such that the
#  congruences U'*C_Îº*U are as diagonal as possible for all Îº=1:k.
#  `tol` is the convergence to be attained.
#  `maxiter` is the maximum number of iterations allowed.
#  if `updateRule`=`:angle` (default), the max abs of the sin of the angle
#  across all pairs is used as stopping criterion, otherwise (any other symbol)
#  the max abs of the Riemannian gradient entry is used.
#  The former is the usual choice of the JADE algorithm, the latter allows to
#  compare directly the execution speed of JADE and JADEmax as JADEmax uses
#  that stopping criterion. Note that the Riemannian gradient criterion for 
#  JADE can be obtained at virtually no extra-cost from the computation of
#  the angle.
#  if `verbose`=true, the convergence attained at each iteration and other
#  information will be printed.
#
#  RETURN: B, the number of iterations and the convergence attained (a 3-tuple)
function jade(C::Matrix{T};
				tol 	 = 0.,
				maxiter = 1000,
				updateRule = :angle,
				verbose = false) where T<:Union{Real, Complex}

	(n, nk) = size(C)
	iter, conv, ğŸ˜‹, k, U = 1, 1., false, nkÃ·n, Matrix{T}(I, n, n)
	tolerance = tolâ‰¤0. ? âˆšeps(real(T)) : tol
	eâ‚, eâ‚‚, eâ‚ƒ, Î¦, Î¦â‚œ = jadeAllocateMemory(T, k)

	verbose && @info("Iterating JADE algorithm...")
	while true
		conv = updateRule==:angle ? cyclicSweepAngle!(C, eâ‚, eâ‚‚, eâ‚ƒ, Î¦, Î¦â‚œ, U, n, nk, tolerance) :
			   						cyclicSweepGradient!(C, eâ‚, eâ‚‚, eâ‚ƒ, Î¦, Î¦â‚œ, U, n, nk, tolerance)
		verbose && println("iteration: ", iter, "; convergence: ", conv)
	   	(overRun = iter == maxiter) && @warn("JADE reached the max number of iterations before convergence:", iter)
	   	(ğŸ˜‹ = conv <= tolerance) || overRun==true ? break : iter += 1
	end
	verbose && @info("Convergence has "*(ğŸ˜‹ ? "" : "not ")*"been attained.\n\n")

	return U, iter, conv
end



## PRIMITIVE JADEmax algorithm:
#  It takes as input a nÂ·nk matrix holding k horizontally stacked nÂ·n real or
#  complex matrices, such as C=[C_1...C_k].
#  It finds an orthogoanl/unitary matrix U such that the
#  congruences U'*C_Îº*U are as diagonal as possible for all Îº=1:k.
#  `tol` is the convergence to be attained.
#  `maxiter` is the maximum number of iterations allowed.
#  if `verbose`=true, the convergence attained at each iteration and other
#  information will be printed.
#
#  RETURN: B, the number of iterations and the convergence attained (a 3-tuple)
function jademax(C::Matrix{T};
					tol 	 = 0.,
					maxiter = 1000,
					verbose = false) where T<:Union{Real, Complex}
	(n, nk) = size(C)
	k, N, U, p, q = nkÃ·n, (n*(n-1))Ã·2, Matrix{T}(I, n, n), 0, 0
	ğ“¹â‚, ğ“¹â‚‚ = 1:n:nk, n:n:nk
	ğ“¹, ğ“º = ğ“¹â‚, ğ“¹â‚‚
	tolerance = tolâ‰¤0. ? âˆšeps(real(T)) : tol
	iter, itN, itN0, conv, ğŸ˜‹ = 0, 1, 0, 1., false
	eâ‚, eâ‚‚, eâ‚ƒ, Î¦, Î¦â‚œ = jadeAllocateMemory(T, k)
	D=[Vector{T}(undef, n) for i=1:k]

	verbose && @info("Iterating JADEmax algorithm...")
	# compute the full gradient only once at the beginning
	âˆ‡ = jadeRiemannianâˆ‡(C, D, n, k, ğ“¹â‚, ğ“¹â‚‚)
    while true
		# find max absolute element of the gradient and its position
		conv, maxpos = T <:Real ? findmax(âˆ‡) : findmax(abs2.(âˆ‡))
		p, q = maxpos[1], maxpos[2]
		ğ“¹, ğ“º  = p:n:nk, q:n:nk
		# find angle, update U, all Câ‚– matrices and the Riemannian gradient
	  	c, s, âˆ¡ = givensAngle(C, p, q, ğ“¹, ğ“º, eâ‚, eâ‚‚, eâ‚ƒ, Î¦, Î¦â‚œ)
		if conv > tolerance
			jadeUpdate!(U, C, c, s, p, q, ğ“¹, ğ“º)
			jadeRiemannianâˆ‡Update!(âˆ‡, C, D, k, p, q, ğ“¹, ğ“º, ğ“¹â‚, ğ“¹â‚‚)
		end

		(itN0=itN%N==0) && (iter+=1)
		verbose && itN0 && println("iteration(m): ", iter, "; convergence: ", conv)
		(overRun = iter == maxiter) && @warn("jademax reached the max number of iterations before convergence:", iter)
       	(ğŸ˜‹ = conv <= tolerance) || overRun==true ? break : itN += 1
    end
	verbose && !itN0 && println("iteration(m): ", iter, " + ", itN%N, " sweeps ; convergence: ", conv)
    verbose && @info("Convergence has "*(ğŸ˜‹ ? "" : "not ")*"been attained.\n\n")

	return U, iter, conv
end



#  ADVANCED JADE and JADEmax algorithms:
#  They take as input a vector of k real symmetric or complex Hermitian
#  matrices ğ‚ and finds an orthogoanl/Unitary matrix U such that the
#  congruences U'*ğ‚_Îº*U are as diagonal as possible for all Îº=1:k.
#
#  if `trace1` is true (false by default), all input matrices are normalized
#  so as to have unit trace. Note that the diagonal elements
#  of the input matrices must be all positive.
#
#  `w` is an optional vector of k positive weights for each matrix in ğ‚.
#  if `w` is different from `nothing` (default), the input matrices are
#  weighted with these weights (after trace normalization if `trace1` is true).
#  A function can be passed as the `w` argument, in which case the kth weight
#  is found as the output of the function applied to the kth matrix in ğ‚.
#  A good choice in general is the `nonD` function declared in tools.jl unit.
#
#  if `whitening` = true is passed, the Arithmetic mean of the matrices in ğ‚ is
#  computed (using the PosDefManifold.jl package) and the matrices in ğ‚
#  are pre-transformed using the whitening matrix of the mean.
#  Dimensionality reduction can be obtained at this stage using optional
#  arguments `eVar` and `eVarMeth` (see documentation of the AJD constructors).
#
#  if sort=true (default) the column vectors of the B matrix are reordered
#  so as to sort in descending order the mean of the diagonal elements
#  of B'*ğ‚_Îº* over k.
#
#  if  `whitening` = false (default), a matrix can be provided with the `init`
#  argument in order to initialize B. In this case the actual AJD
#  will be given by init*B, where B is the output of the algorithms.
#
#  `tol` is the convergence to be attained.
#
#  `maxiter` is the maximum number of iterations allowed.
#
#  if `verbose`=true, the convergence attained at each iteration and other
#  information will be printed.
#
#  return: B, its pseudo-inverse, the mean diagonal elements of B'*mean(ğ‚)*B,
#          the number of iterations and the convergence attained
function jade( ğ‚::Union{Vector{Hermitian}, Vector{Symmetric}};
               trace1   :: Bool  = false,
               w        :: Twf   = â—‹,
               preWhite :: Bool  = false,
               sort     :: Bool  = true,
               init     :: Union{Matrix, Nothing} = â—‹,
               tol      :: Real  = 0.,
               maxiter  :: Int   = 1000,
               verbose  :: Bool  = false,
            eVar     :: TeVaro = â—‹,
            eVarMeth :: Function = searchsortedfirst)

	# trace normalization and weighting
	ğ† = _normalizeAndWeight(trace1, w, ğ‚)

	# pre-whiten or initialize and stack matrices horizontally
	W, C = _preWhiteOrInit(ğ‚, preWhite, Euclidean, eVar, eVarMeth, init, :stacked)

	(n, nk) = size(C)

	U, iter, conv = jade(C; tol=tol, maxiter=maxiter, verbose=verbose)

	# permute the vectors of U
	D=Diagonal([mean(C[i, i:n:nk]) for i=1:n])
	Î» = sort ? _permute!(U, D, n) : diag(D)

	return preWhite ? (W.F*U, U'*W.iF, Î», iter, conv) :
	                  (U, Matrix(U'), Î», iter, conv)
end


function jademax( ğ‚::Union{Vector{Hermitian}, Vector{Symmetric}};
               trace1   :: Bool  = false,
               w        :: Twf   = â—‹,
               preWhite :: Bool  = false,
               sort     :: Bool  = true,
               init     :: Union{Matrix, Nothing} = â—‹,
               tol      :: Real  = 0.,
               maxiter  :: Int   = 1000,
               verbose  :: Bool  = false,
            eVar     :: TeVaro = â—‹,
            eVarMeth :: Function = searchsortedfirst)

	# trace normalization and weighting
	ğ† = _normalizeAndWeight(trace1, w, ğ‚)

	# pre-whiten or initialize and stack matrices horizontally
	W, C = _preWhiteOrInit(ğ‚, preWhite, Euclidean, eVar, eVarMeth, init, :stacked)

	(n, nk) = size(C)

	U, iter, conv = jademax(C; tol=tol, maxiter=maxiter, verbose=verbose)

	# permute the vectors of U
	D=Diagonal([mean(C[i, i:n:nk]) for i=1:n])
	Î» = sort ? _permute!(U, D, n) : diag(D)

	return preWhite ? (W.F*U, U'*W.iF, Î», iter, conv) :
	                  (U, Matrix(U'), Î», iter, conv)
end
