#   Unit "tools.jl" of the Diagonalization.jl Package for Julia language
#
#   MIT License
#   Copyright (c) 2019, 2020
#   Marco Congedo, CNRS, Grenoble, France:
#   https://sites.google.com/site/marcocongedo/home

# ? CONTENTS :
#   This unit implements general tools and internal functions.

"""
```
function eig(A)

function eig(A, B)
```
Call Julia function [eigen](https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/#LinearAlgebra.eigen)
and return its output sorted by descending
order of eigenvalues.
"""
function eig(A)
   Î», U=eigen(A)
   return (reverse(Î»), reverse(U, dims=2))
end

function eig(A, B)
   Î», U=eigen(A, B)
   return (reverse(Î»), reverse(U, dims=2))
end


"""
```
function nonDiagonality(C::Union{Matrix, Diagonal, SorH})
```

Measure of deviancy from diagonality of ``nâ‹…n`` square matrix `C`, defined as
(Congedo et al., 2008)[ğŸ“](@ref).

``\\frac{\\sum_{iâ‰ j}|c_{ij}|^2}{(n-1)\\sum_{i}|c_{ii}|^2}``

It is equal to ``0`` if ``C`` is diagonal, equal to ``1`` if
``C`` is perfectly uniform.

**Examples:**
```
using Diagonalizations
C=ones(10, 10)                   # uniform matrix
nd=nonDiagonality(C)             # must be 1
D=Diagonal(abs.(randn(10, 10)))  # diagonal matrix
nd=nonDiagonality(D)             # must be 0
```
"""
function nonDiagonality(C::Union{Matrix, Diagonal, SorH})
   n = size(C, 1)
   n â‰  size(C, 2) && throw(ArgumentError("ğŸ“Œ, nonDiagonality function: input matrix must be square"))
   ssDiag=sumOfSqrDiag(C)
   return ((sumOfSqr(C)-ssDiag)/ssDiag)/(n-1)
end
nonD=nonDiagonality


"""
```
function spForm(P::Union{Mat, Real, Complex})
```
Measure of deviancy from scaled permutation form of ``nâ‹…n`` square matrix
`P`, defined as

``\\frac{1}{2(n-1)}\\bigg(\\sum_{row}1-\\beta(row)+\\sum_{col}1-\\beta(col)\\bigg)``,

where for each *row* and *column* of `P`, Î² is the maximum of the
absolute values divided by the sum of the absolute values.

This index is equal to ``0`` if in each row and column ``P``
has only one non-zero element, that is, if ``P`` is a scaled permutation matrix.
The larger the index, the farther away ``P`` is from this form.

This measure and several existing variants are well-known in the blind source
separation / independent component analysis community,
where it is used to compare approximate joint diagonalization
algorithms on simulated data. In fact, if ``A`` is the inverse of the
approximate joint diagonalizer that is used to generate the data
and ``B`` the approximate joint diagonalizer estimated by an algorithm,
``P=BA`` must be as close as possible to a scaled permutation matrix
(see [scale and permutation](@ref)).

Return 0.0 (zero) if `P` is a real of complex number.

**Examples:**

```
using Diagonalizations, PosDefManifold
# create 20 random commuting matrices
# they all have the same eigenvectors
Cset=randP(3, 20; eigvalsSNR=Inf, commuting=true)
# estimate the approximate joint diagonalizer (ajd)
a=ajd(Cset)
# the ajd must be equivalent to the eigenvector matrix of
# any of the matrices in Cset
spForm(a.F'*eigvecs(Cset[1]))+1.0â‰ˆ1.0 ? println(" â­ ") : println(" â›” ")
```

"""
function spForm(P::Union{Mat, Real, Complex})
   if P isa Number return 0.0 end
   r, c=size(P)
   r â‰  c && throw(ArgumentError("ğŸ“Œ, spForm function: input matrix must be square"))
   mos(v::AbstractArray)=1.0-(maximum(v)/sum(v)) # 1- max over sum of a vector
   (sum(mos(abs.(p)) for pâˆˆeachcol(P)) + sum(mos(abs.(p)) for pâˆˆeachrow(P)))/(2*(r-1))
end



"""
```
(1)
function genDataMatrix(t::Int, n::Int, A=nothing)

(2)
function genDataMatrix(::Type{Complex{T}},
                       t::Int, n::Int, A=â—‹) where {T<:AbstractFloat}
```

(1)
Generate a ``tâ‹…n`` random data matrix as ``XA``,
where ``X`` is a ``tâ‹…n`` matrix with entries randomly drawn
from a Gaussian distribution and ``A`` a ``nâ‹…n`` symmetric
matrix, which, if not provided as argument `A`,
will be generated with entries randomly drawn from a uniform
distribution âˆˆ[-1, 1].

(2)
as (1), but ``X`` is generated randomly from a complex
Gaussian distribution and ``A``is Hermitian (complex)
which, if not provided as argument `A`,
will be generated with entries randomly drawn from a uniform
distribution âˆˆ[-1-i1, 1+i1].

**Examples:**

A=genDataMatrix(100, 20) # (1), real
A=genDataMatrix(ComplexF64, 100, 20) # (2), complex

"""
function genDataMatrix(t::Int, n::Int, A=â—‹)
   if A===â—‹ A=Symmetric((rand(n, n).-0.5).*2) end
   return randn(t, n)*A
end

function genDataMatrix(::Type{Complex{T}},
                       t::Int, n::Int, A=â—‹) where {T<:AbstractFloat}
  if A===â—‹ A=Hermitian([(rand(T).-(0.5+0.5im)).*2. for i=1:n, j=1:n]) end
  return randn(T, t, n)*A
end
# -------------------------------------------------------- #
# INTERNAL FUNCTIONS #
# -------------------------------------------------------- #


# EigenDecomposition with a covariance matrix as input
function _getEVD(C :: Union{Hermitian, Symmetric, Mat}, eVar::TeVaro,
                 eVarMeth::Function, simple::Bool)

   Î», U = eig(C)
   Î»=_checkÎ»(Î») # make sure no imaginary noise is present (fro complex data)
   simple ? (U, Matrix(U'), Diagonal(Î»), â—‹, â—‹, â—‹) :
   begin
     eVar===â—‹ ? eVar=0.999 : â—‹
     eVar, D, U, p, arev=_ssd!(eVar, Î», U, _minDim(C), eVarMeth)
     (U, Matrix(U'), D, eVar, Î», arev)
   end
end


# EigenDecomposition with a data matrix as input
_getEVD(X::Mat, covEst::StatsBase.CovarianceEstimator, dims::Int64,
        mean::Tmean, w::Tw, eVar::TeVaro, eVarMeth::Function, simple::Bool) =
  _getEVD(_cov(X, covEst, dims, mean, w), eVar, eVarMeth, simple)


# Whitening with a covariance matrix as input
function _getWhi(C :: Union{Hermitian, Symmetric, Mat}, eVar::TeVaro,
                 eVarMeth::Function, simple::Bool)

  U, Uâ±, D, eVar, Î», arev=_getEVD(C, eVar, eVarMeth, simple)
  simple ? (U*D^-0.5, D^0.5*Uâ±, D, â—‹, â—‹, â—‹) :
           (U*D^-0.5, D^0.5*Uâ±, D, eVar, Î», arev)
end

# Whitening with a data matrix as input
_getWhi(X::Mat, covEst::StatsBase.CovarianceEstimator, dims::Int64,
        mean::Tmean, w::Tw, eVar::TeVaro, eVarMeth::Function, simple::Bool) =
   _getWhi(_cov(X, covEst, dims, mean, w), eVar, eVarMeth, simple)


# convert mean vector for compatibility with StatsBase.jl
function _convert_mean(mean::Tmean, dims::Int, argName::String)
  length(mean)â‰ n && throw(ArgumentError(ğŸ“Œ*", _convert_mean internal function: vector "*argName*" must have length $n"))
  return dims==1 ? Matrix(mean') : mean
end

# return `X` or `X` with the mean subtracted, depending on `meanX`
function _deMean(X::Mat, dims::Int, meanX::Tmean)
   if       meanX isa Int
            return X
   elseif   meanX===â—‹
            meanX_=mean(X; dims=dims)
   elseif   meanX isa AbstractVector
            meanX_=_convert_mean(meanX, dims, "meanX")
   end
   #println("dims ", dims, "  sizemeanX_ ", size(meanX_), " sizeX ", size(X))
   if       dims==1
            s=(1, size(X, 2))
   elseif   dims==2
            s=(size(X, 1), 1)
   end
   size(meanX_)â‰ s && throw(ArgumentError(ğŸ“Œ*", _deMean internal function: The size of `meanX_` does not fit input matrix `X` with `dims`=$dims"))
   return X.-meanX_
end

# check arguments for one data matrix input
function _check_data(X::Mat, dims::Int64, covEst::StatsBase.CovarianceEstimator, meanX::Tmean, wX::Tw)
   dims âˆˆ (1, 2) || throw(ArgumentError(ğŸ“Œ*", _check-data internal function: Argument `dims` may be 1 or 2. dims=$dims"))
   wXâ‰ â—‹ && lenght(wX)â‰ size(X, dims) && throw(ArgumentError(ğŸ“Œ*", _check-data internal function: The size of `wX` does not fit input matrix `X` with `dims`=$dims"))
   eltype(X)<:Complex && covEstâ‰ SCM && throw(ArgumentError(ğŸ“Œ*", _check-data internal function: Only the `SCM` (sample covariance matrix) `covEst` estimator can be used for complex data"))
   # TODO add check for meanX
   ishermitian(X) && throw(ArgumentError(ğŸ“Œ*", _check-data internal function: it looks like
   you want to call a filter constuctor that takes covariance matrices as input,
   but you are actually calling the constructor that takes data matrices as input.
   Solution: flag your covariance matrix(ces) argument(s) as Symmetric or Hermitian,
   for example, `Hermitian(C)`. To do so, you will need to be using LinearAlgebra."))
   return true
end

# check arguments for two data matrices input
function _check_data(X::Mat, Y::Mat, dims::Int64, covEst::StatsBase.CovarianceEstimator, meanX::Tmean, meanY::Tmean, wXY::Tw)
   dims âˆˆ (1, 2) || throw(ArgumentError(ğŸ“Œ*", _check-data internal function: Argument `dims` may be 1 or 2. dims=$dims"))
   size(X, dims)==size(Y, dims) || throw(ArgumentError(ğŸ“Œ*", _check-data internal function: The `dims` dimension of argument `X` and `Y` must be the same"))
   wXYâ‰ â—‹ && lenght(wXY)â‰ size(X, dims) && throw(ArgumentError(ğŸ“Œ*", _check-data internal function: The size of `wXY` does not fit input matrix `X` with `dims`=$dims"))
   (eltype(X)<:Complex || eltype(Y)<:Complex) && covEstâ‰ SCM && throw(ArgumentError(ğŸ“Œ*", _check-data internal function: Only the `SCM` (sample covariance matrix) `covEst` estimator can be used for complex data"))
   # TODO add check for meanX and meanY
   return true
end


# check arguments for one vector of data matrix input
function _check_data(ğ—::VecMat, dims::Int64, covEst::StatsBase.CovarianceEstimator, meanX::Into, w::Twf)
   dims âˆˆ (1, 2) || throw(ArgumentError(ğŸ“Œ*", _check-data internal function: Argument `dims` may be 1 or 2. dims=$dims"))
   x=collect(size(X, _flip12(dims)) for X âˆˆ ğ—)
   all(y->y==x[1], x) ||  throw(ArgumentError(ğŸ“Œ*", _check-data internal function: Given `dims`=$dims, all matrices in `ğ—` must have the same dimension $(_flip12(dims))"))
   wâ‰ â—‹ && !(w isa Function) && lenght(w)â‰ length(ğ—) && throw(ArgumentError(ğŸ“Œ*", _check-data internal function: The size of `w` must be equal to the number of matrices in `ğ—`"))
   !isempty(findall(x->eltype(x)<:Complex, ğ—)) && covEstâ‰ SCM && throw(ArgumentError(ğŸ“Œ*", _check-data internal function: Only the `SCM` (sample covariance matrix) `covEst` estimator can be used for complex data"))
   # TODO add check for meanX
   return true
end

# check arguments for two vectors of data matrix input
function _check_data(ğ—::VecMat, ğ˜::VecMat, dims::Int64, covEst::StatsBase.CovarianceEstimator, meanX::Into, meanY::Into, w::Twf)
   dims âˆˆ (1, 2) || throw(ArgumentError(ğŸ“Œ*", _check-data internal function: Argument `dims` may be 1 or 2. dims=$dims"))
   length(ğ—)==length(ğ˜) || throw(ArgumentError(ğŸ“Œ*", _check-data internal function: The number of matrices in `ğ—` and `ğ˜` must be the same"))
   x=collect(size(X, dims)-size(Y, dims) for (X, Y) âˆˆ (ğ—, ğ˜))
   norm(x)==0 || throw(ArgumentError(ğŸ“Œ*", _check-data internal function: The `dims` dimension of all pairs of matrices in `ğ—` and `ğ˜` must be the same"))
   wâ‰ â—‹ && !(w isa Function) && lenght(w)â‰ length(ğ—) && throw(ArgumentError(ğŸ“Œ*", _check-data internal function: The size of `w` must be equal to the number of matrices in `ğ—` and `ğ˜`"))
   (!isempty(findall(x->eltype(x)<:Complex, ğ—)) || !isempty(findall(y->eltype(y)<:Complex, ğ˜))) && covEstâ‰ SCM && throw(ArgumentError(ğŸ“Œ*", _check-data internal function: Only the `SCM` (sample covariance matrix) `covEst` estimator can be used for complex data"))
   # TODO add check for meanX and meanY
   return true
end

#TODO _check_data(ğ‘¿::VecVecMat, dims::Int64, covEst::StatsBase.CovarianceEstimator, meanX::Into, â—‹)===â—‹ && return

# call StatsBase.cov within one line with or without weights
# Also, flag the covariance as Symmetric if is real, Hermitian if is complex
# The mean is subtracted separatedly for consistence with the other _cov method
# NB!!! covarianceestimations.jl does not work for complex data input!
function _cov(X::Matrix{R},
              covEst   :: StatsBase.CovarianceEstimator = SCM,
              dims     :: Int64 = 1,
              meanX    :: Tmean = 0,
              wX       :: Tw = â—‹) where R<:Real
   #T = R isa Real ? Symmetric : Hermitian
   X_=_deMean(X, dims, meanX)
   return wX===â—‹ ? Symmetric(cov(covEst, X_; dims=dims, mean=0)) : # do NOT remove `mean`=0
                   Symmetric(cov(covEst, X_, wX; dims=dims, mean=0)) # "
end

# `covest` is not used but left in for code homogeneity
function _cov(X::Matrix{R},
              covEst   :: StatsBase.CovarianceEstimator = SCM,
              dims     :: Int64 = 1,
              meanX    :: Tmean = 0,
              wX       :: Tw = â—‹) where R<:Complex
   X_=_deMean(X, dims, meanX)
   wXâ‰ â—‹ ? ( dims==1 ? X__=wX.*X_ : X__=wX'.*X_ ) : X__=X_
   return dims==1 ? Hermitian((X__'*X__)/size(X, 1)) : Hermitian((X__*X__')/size(X, 2))
end

# as before for a vector of data matrices at once
# NB!!! does not work for complex data input as uses the above method!
function _cov(ğ—::VecMat;
              covEst   :: StatsBase.CovarianceEstimator = SCM,
              dims     :: Int64 = 1,
              meanX    :: Into = 0)
   # once PosDefManifold supports vectors of Symmetric matrices
   # T = R===Real ? Symmetric : Hermitian
   # remove `Hermitian` here below and use T instead
   # _cov will automatically flag its output
   ğ‚=Vector{Hermitian}(undef, length(ğ—))
   @threads for i=1:length(ğ—)
               ğ‚[i]=Hermitian(_cov(ğ—[i], covEst, dims, meanX, â—‹))
   end
   return ğ‚
end


# cross-covariance within one line with or without weights
# The mean is subtracted separately since there is no crosscov method in StatsBase
function _cov(X::Matrix{R}, Y::Matrix{R},
              dims     :: Int64 = 1,
              meanX    :: Tmean = 0,
              meanY    :: Tmean = 0,
              wXY      :: Tw = â—‹) where R<:Union{Real, Complex}
   (size(X, dims) â‰  size(Y, dims)) && throw(ArgumentError(ğŸ“Œ*", _cov internal function: the size of matrices `X` and `Y` are not conform for computing cross-covariance with $dims as value of `dims`"))
   X_=_deMean(X, dims, meanX)
   Y_=_deMean(Y, dims, meanY)
   return wXY===â—‹ ? ( dims==1 ? (X_'*Y_)/size(X, 1) : (X_*Y_')/size(X_, 2) ) :
                    ( dims==1 ? ((wXY'.*X_')*Y_)/wXY.sum : ((wXY'.*X_)*Y_')/wXY.sum )
end

# The same as above, for 2 vectors of data matrices at once
# the cross-covariance if computed for all corresponding pairs
function _cov(ğ—::VecMat, ğ˜::VecMat;
              dims     :: Int64 = 1,
              meanX    :: Into = 0,
              meanY    :: Into = 0)
   (length(ğ—)â‰ length(ğ˜)) && throw(ArgumentError(ğŸ“Œ*", _cov internal function: vectors ğ— and ğ˜ must hold the same number of data matrices"))
   ğ‚=Vector{Matrix}(undef, length(ğ—))
   @threads for i=1:length(ğ—)
               ğ‚[i]=_cov(ğ—[i], ğ˜[i], dims, meanX, meanY, â—‹)
            end
   return ğ‚
end

# trace normalize and/or apply weights. Accept a function for computing weights
# only for m=1
function _Normalize!(ğ‚::Vector{Hermitian},
                     trace1::Bool=false, w::Union{Tw, Function}=â—‹)
   !trace1 && w===â—‹ && return
   k=length(ğ‚)

   if trace1
      @inbounds for Îº=1:k ğ‚[Îº] = tr1(ğ‚[Îº]) end
   end
   if w isa Function
      w=[w(ğ‚[Îº]) for Îº=1:k]
   end
   if w â‰  â—‹
      @inbounds for Îº=1:k ğ‚[Îº] *= w[Îº] end
   end
end

# trace normalize and/or apply weights. Accept a function for computing weights
# m>=1, k>=1. ğ’ is a 3-D Array of matrices (k, i, j), i, j=1:m
function _Normalize!(ğ’::AbstractArray, m::Int, k::Int,
                     trace1::Bool=false, w::Union{Tw, Function}=â—‹)
   !trace1 && w===â—‹ && return

   #for Îº=1:k println(tr(ğ’[Îº, 1, 1])) end

   if m==1
      if trace1
         @inbounds for Îº=1:k ğ’[Îº, 1, 1] = tr1(ğ’[Îº, 1, 1]) end
      end
      if w isa Function
         w=[w(ğ’[Îº, 1, 1]) for Îº=1:k]
      end
      if w â‰  â—‹
         @inbounds for Îº=1:k ğ’[Îº, 1, 1] *= w[Îº] end
      end
   else
      for Îº=1:k
         if trace1
               t=[1/sqrt(tr(ğ’[Îº, i, i])) for i=1:m]
         elseif w â‰  â—‹
               t=ones(eltype(ğ’[1, 1, 1]), m)
         end
         if     w isa Function
                  @inbounds for i=1:m t[i]*=sqrt(w(ğ’[Îº, i, i])) end
         elseif w isa StatsBase.AbstractWeights
                  @inbounds for i=1:m t[i]*=sqrt(w[i]) end
         end
         if trace1 || w â‰  â—‹
           @inbounds for i=1:m, j=i:m ğ’[Îº, i, j] = ğ’[Îº, i, j]*(t[i]*t[j]) end
         end
      end
   end
end


# if     m=1 ğ— is a vector of k data matrices.
#           Return a kx1x1 array of their covariance matrices in the k dimension
# elseif k=1 ğ— is a vector of m data matrices.
#           Return a 1xmxm array of all cross-covariances of ğ—[i] and ğ—[j], for i,j=1:m
# elseif ğ— is a k-vector of m data matrices.
#           Return a kxmxm array of all cross-covariances of ğ—[l][i] and ğ—[l][j], for l=1:k, i,j=1:m
function _crossCov(ğ—, m, k;
                   covEst  :: StatsBase.CovarianceEstimator=SCM,
                   dims    :: Int64 = 1,
                   meanX   :: Into = 0,
                   trace1  :: Bool = false,
                   w       :: Union{Tw, Function}=â—‹)
    ğ’=Array{Matrix}(undef, k, m, m)
    if      m==1
      @inbounds for Îº=1:k ğ’[Îº, 1, 1] = _cov(ğ—[Îº], covEst, dims, meanX, â—‹) end
    elseif  k==1
      @inbounds for i=1:m-1, j=i+1:m
                        ğ’[1, i, j] = _cov(ğ—[i], ğ—[j], dims, meanX, meanX, â—‹)
                        ğ’[1, j, i] = ğ’[1, i, j]'
                end
      @inbounds for i=1:m ğ’[1, i, i] = _cov(ğ—[i], covEst, dims, meanX, â—‹) end # This is needed for scaling in any case
    else
      @inbounds for Îº=1:k, i=1:m-1, j=i+1:m
                        ğ’[Îº, i, j] = _cov(ğ—[Îº][i], ğ—[Îº][j], dims, meanX, meanX, â—‹)
                        ğ’[Îº, j, i]=ğ’[Îº, i, j]'
                end
      @inbounds for Îº=1:k, i=1:m ğ’[Îº, i, i] = _cov(ğ—[Îº][i], covEst, dims, meanX, â—‹) end # This is needed for scaling in any case
    end

    # trace normalize
    if trace1 || w â‰  â—‹ _Normalize!(ğ’, m, k, trace1, w) end

    return ğ’
end



# get index and value of the
# first value in ğœ† greater than or equal to eVar (eVarMeth=searchsortedfirst) or
# last value in ğœ† less than or equal to eVar (eVarMeth=searchsortedlast),
# where ğœ† is the vector with accumulated regularized (sum-normalized) eigenvalues
# INPUT:
# the desired explained variance (real) of subspace dimension (int) (evar),
# the eigenvalues in descending order (Î»),
# the corresponding eigenvectors (U),
# the maximum theoretical rank of the input matrix (r),
# the method (eVarMeth function) for determining the subspace dimension.
# OUTPUT:
# the actual explained variance (evar!),
# the first p eigenvalues (Î»!),
# the corresponding first p eigenvectors (U!),
# the subspace dimension (p),
# the vector with the accumulated regularized eigenvalues (arev)

function _getssd!(eVar::TeVaro, Î»::Vec, r::Int64, eVarMeth::Function)
   eltype(Î»)<:Complex && @warn "ğŸ“Œ, internal function `_getssd!`: the `Î»` vector is complex, subspace dimension is based on its absolute values."
   eVar===â—‹ ? eVar=0.999 : â—‹
   Î»_=abs.(Î»)
   arev = accumulate(+, Î»_./sum(Î»_))
   return (eVar isa Int64 ? clamp(eVar, 1, r) : clamp(eVarMeth(arev, eVar), 1, r), arev)
end

#see PCA and Whitening
function _ssd!(eVar::TeVaro, Î»::Vec, U::Mat, r::Int64, eVarMeth::Function)
   eltype(Î»)<:Complex && @warn "ğŸ“Œ, internal function `_ssd!`: the `Î»` vector is complex, subspace dimension is based on its absolute values."
   p, arev = _getssd!(eVar, Î», r, eVarMeth)
   return p==r ? 1. : arev[p], Diagonal(Î»[1:p]), U[:, 1:p], p, arev
end

#see PMCA and CCA
function _ssdxy!(eVar::TeVaro, Î»::Vec, U1::Mat, U2::Mat, r::Int64, eVarMeth::Function)
   eltype(Î»)<:Complex && @warn "ğŸ“Œ, internal function `_ssdxy!`: the `Î»` vector is complex, subspace dimension  is based on its absolute values."
   p, arev = _getssd!(eVar, Î», r, eVarMeth)
   return p==r ? 1. : arev[p], Diagonal(Î»[1:p]), U1[:, 1:p], U2[:, 1:p], p, arev
end

# see CSP
function _ssdcsp!(eVar::TeVaro, Î»::Vec, U::Mat, r::Int64, eVarMeth::Function, selMeth::Symbol)
   eltype(Î»)<:Complex && @warn "ğŸ“Œ, internal function `_ssdcsp!`: the `Î»` vector is complex, subspace dimension  is based on its absolute values."
   Î»_=abs.(Î»)
   ratio = Î»_./(1.0.-Î»_)
   d = (log.(ratio)).^2
   h = selMeth==:extremal ? sortperm(d; rev=true) : [i for i=1:length(Î»)]
   arev = accumulate(+, d[h]./sum(d))
   if     eVar isa Int
      p = clamp(eVar, 1, r)
   elseif eVar isa Real
      p = clamp(eVarMeth(arev, eVar), 1, r)
   else    #eVar isa nothing, the default
      if selMeth==:extremal
         g=exp(sum(log, d)/length(d))
         p = clamp(searchsortedlast(d[h], g; rev=true), 1, r)
      else
         p = clamp(searchsortedlast(ratio, 1; rev=true), 1, clamp(argmin(d), 1, r))
      end
   end
   return p==r ? 1. : arev[p], Diagonal(Î»[h[1:p]]), U[:, h[1:p]], p, arev
end

# see CSTP
function _ssdcstp!(eVar::TeVaro, Î»::Vec, U::Mat, V::Mat, r::Int64, eVarMeth::Function)
   eltype(Î»)<:Complex && @warn "ğŸ“Œ, internal function `_ssdcstp!`: the `Î»` vector is complex, subspace dimension is based on its absolute values."
   Î»_=abs.(Î»)
   arev = accumulate(+, Î»_./sum(Î»_))
   if     eVar isa Int
      p = clamp(eVar, 1, r)
   elseif eVar isa Real
      p = clamp(eVarMeth(arev, eVar), 1, r)
   else    #eVar isa nothing, the default
      p = clamp(eVarMeth(arev, 0.999), 1, r)
   end
   return p==r ? 1. : arev[p], Diagonal(Î»[1:p]), U[:, 1:p], V[:, 1:p], p, arev
end


_flip12(i::Int) =
   if      i==1 return 2
   elseif  i==2 return 1
   else throw(ArgumentError, ğŸ“Œ*", _flip12 internal function: the `dims` argument must be 1 or 2")
   end


_set_dims(X::Mat)=argmax(collect(size(X)))
_set_dims(X::Mat, Y::Mat)=argmax(collect(size(X))+collect(size(Y)))
_set_dims(ğ—::VecMat)=argmax(sum(collect(size(X)) for X âˆˆ ğ—))
_set_dims(ğ—::VecMat, ğ˜::VecMat)=
    argmax(sum(collect(size(X)) for X âˆˆ ğ—)+sum(collect(size(Y)) for Y âˆˆ ğ˜))
_set_dims(ğ‘¿::VecVecMat)=argmax(sum(collect(size(ğ‘¿[i][j])) for i=1:length(ğ‘¿) for j=1:length(ğ‘¿[i])) )


_minDim(X::Matrix) = minimum(size(X))
_minDim(X::Matrix, Y::Matrix) = min(minimum(size(X)), minimum(size(Y)))
_minDim(C::SorH) = size(C, 1)
_minDim(ğ‚::â„Vector) = minimum(size(C, 1) for C âˆˆ ğ‚)
_minDim(C1::SorH, C2::SorH) = min(size(C1, 1), size(C2, 1))
_minDim(ğ—::VecMat) = minimum(minimum(size(X)) for X âˆˆ ğ—)
_minDim(ğ—::VecMat, ğ˜::VecMat) = min(_minDim(ğ—), _minDim(ğ˜))
_minDim(ğ‘¿::VecVecMat) = minimum((minimum(minimum(size(X)) for X âˆˆ ğ‘¿[i]) for i=1:length(ğ‘¿)))


### tools for AJD Algorithms ###

# get the maximum number of iterations for each algorithm depending on the
# data input type if the algorithm supports both real and complex data input
_maxiter(algorithm, type) =
   if       algorithm âˆˆ (:OJoB, :NoJoB)
            return type<:Real ? 1000 : 3000
   elseif   algorithm âˆˆ (:LogLike, :LogLikeR, :JADE)
            return type<:Real ? 60 : 180
   else throw(ArgumentError("The `algorithm` keyword is uncorrect"))
   end


# take as input the vector `Î»` of diagonal elements of transformed diagonalized
# matrices. Check that the imaginary part of Î» is close to zero.
# If so, return a vector with the real part of Î»,
# otherwise print a warning and return Î».
function _checkÎ»(Î»::Vec)
   rePart=sum(real(Î»).^2)
   imPart=sum(imag(Î»).^2)
   if imPart/rePart > 1e-6
      @warn "ğŸ“Œ, internal function _permute!: sum_Îº=1^k trace(imag(Diagonal(F'*C_k*F))^2) / trace(imag(Diagonal(F'*C_k*F))^2) > 1e-6. The elements of fields `D`, `ev` and `arev` of the constructed LinearFilter will be complex. See documentation"
      return Î»
   else
      return real(Î»)
   end
end


# try to resolve the permutation for the output of AJD algorithms
# for the case m=1
# return a vector holding the n 'average eigenvalues' Î»1,...,Î»n,
# arranging them in average descending order,
# where Î»Î·=ğ›_i=1:k(Di[Î·, Î·])
function _permute!(U::AbstractArray, D::Diagonal, n::Int)
   type=eltype(D)

   function flipcol!(U::AbstractArray, Î·::Int, e::Int)
      temp=U[:, e]
      U[:, e]=U[:, Î·]
      U[:, Î·]=temp
   end

   for e=1:n  # for all variables find the position of the absolute maximum
      p, max=e, zero(real(type))
      for Î·=e:n
           absd=abs(D[Î·, Î·])
           if  absd > max
               max = absd
               p=Î·
           end
      end

      # Bring the maximum from position Î· on top (current e)
      if pâ‰ e
           flipcol!(U, p, e)
           d=D[p, p]
           D[p, p]=D[e, e]
           D[e, e]=d
      end
   end

   return diag(D)
end


function _permute!(U::AbstractArray, ğ—::AbstractArray,
                   k::Int, input::Symbol;
    covEst   :: StatsBase.CovarianceEstimator=SCM,
    dims     :: Int64 = 1,
    meanX    :: Tmean = 0,
    trace1   :: Bool = false)
    # if n==t the input is assumed to be the covariance matrices
    input==:d ? ğ’=_crossCov(ğ—, 1, k;
                    covEst=covEst, dims=dims, meanX=meanX, trace1=trace1) :
                ğ’=ğ—
    n=size(ğ’[1, 1, 1], 1)

    D=ğ›(ğ”»([U[:, Î·]'*ğ’[l, 1, 1]*U[:, Î·] for Î·=1:n]) for l=1:k)

    return _permute!(U, D, n)
end # function _Permute!



# try to resolve scaling and permutation for the output of mAJD algorithms
# for the case m>1
# return a vector holding the n 'average eigenvalues' Î»1,...,Î»n,
# trying to make them all positive and in descending order as much as possible,
# where Î»Î·=ğ›_iâ‰ j=1:m(Dij[Î·, Î·])
function _scaleAndPermute!( ğ”::AbstractArray, ğ—::AbstractArray,
                            m::Int, k::Int, input::Symbol;
                            covEst   :: StatsBase.CovarianceEstimator=SCM,
                            dims     :: Int64 = 1,
                            meanX    :: Tmean = 0,
                            trace1   :: Bool = false)
    # if input â‰  :d the input is assumed to be the covariance matrices
    input==:d ? ğ’=_crossCov(ğ—, m, k;
                    covEst=covEst, dims=dims, meanX=meanX, trace1=trace1) :
                ğ’=ğ—
    n=size(ğ’[1, 1, 1], 1)

    ğ‘«=ğ”»Vectorâ‚‚(undef, m)
    for i=1:m ğ‘«[i]=ğ”»Vector([ğ›(ğ”»([ğ”[i][:, Î·]'*ğ’[l, i, j]*ğ”[j][:, Î·] for Î·=1:n]) for l=1:k) for j=1:m]) end
    p, type=(1, 1, 1), eltype(ğ‘«[1][1])

    function flipcol!(ğ”::AbstractArray, m::Int, Î·::Int, e::Int)
        for i=1:m
            temp=ğ”[i][:, e]
            ğ”[i][:, e]=ğ”[i][:, Î·]
            ğ”[i][:, Î·]=temp
        end
    end

    for e=1:n  # for all variables  (e.g., electrodes)
        # find the position of the absolute maximum
        max=zero(real(type))
        for i=1:m-1, j=i+1:m, Î·=e:n
            absd=abs(ğ‘«[i][j][Î·, Î·])
            if  absd > max
                max = absd
                p=(i, j, Î·)
            end
        end

        # flip sign of ğ”[j][Î·, Î·] if abs max is negative
        i=p[1]; j=p[2]; Î·=p[3]
        if real(ğ‘«[i][j][Î·, Î·])<0
            ğ”[j][:, Î·] *= -one(type)
        end

        # flip sign of ğ”[j] for all jâ‰ i:1:m if their corresponding element is negative
        for x=1:m
            if xâ‰ j
                if real(ğ‘«[i][x][Î·, Î·])<0
                    ğ”[x][:, Î·] *= -one(type)
                end
            end
        end

        # Bring the maximum from position Î· on top (current e)
        if Î·â‰ e flipcol!(ğ”, m, Î·, e) end

        # compute ğ‘« again
        for i=1:m ğ‘«[i]=ğ”»Vector([ğ›(ğ”»([ğ”[i][:, Î·]'*ğ’[l, i, j]*ğ”[j][:, Î·] for Î·=1:n]) for l=1:k) for j=1:m]) end
    end

    return diag(ğ›(ğ‘«[i][j] for i=1:m for j=1:m if iâ‰ j))
end # function _scaleAndPermute!
